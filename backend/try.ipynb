{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "loader = PyMuPDFLoader(\"sushant_report.pdf\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "chunks = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs), len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(618, 604)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs[0].page_content), len(chunks[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\users\\arraj\\miniconda3\\envs\\torch\\lib\\site-packages (1.9.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\arraj\\miniconda3\\envs\\torch\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\arraj\\miniconda3\\envs\\torch\\lib\\site-packages (from faiss-cpu) (23.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arraj\\AppData\\Local\\Temp\\ipykernel_19484\\912281862.py:1: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embeddings = OllamaEmbeddings(model='nomic-embed-text', base_url=\"http://localhost:11434\")\n"
     ]
    }
   ],
   "source": [
    "embeddings = OllamaEmbeddings(model='nomic-embed-text', base_url=\"http://localhost:11434\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_vector = embeddings.embed_query(\"this is some text data\")\n",
    "index = faiss.IndexFlatL2(len(single_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 768)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = faiss.IndexFlatL2(len(single_vector))\n",
    "index.ntotal, index.d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = vector_store.add_documents(documents=chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.index_to_docstore_id\n",
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0 Hardware / Software Description \n",
      "Scalability in location-based applications depends on an efficient infrastructure, robust \n",
      "software platforms, and effective data management strategies. Here’s an in-depth look at the \n",
      "tools and setup for achieving scalability in LBAs. \n",
      "Software Platforms and Technologies: \n",
      "• \n",
      "Database Systems: \n",
      "o \n",
      "Distributed Databases: Tools like MongoDB, Cassandra, and Google Bigtable offer \n",
      "horizontal scalability, managing data across multiple nodes to handle large user \n",
      "loads. \n",
      "o \n",
      "Spatial Databases: PostgreSQL with PostGIS, or MongoDB’s geospatial capabilities, \n",
      "help with storing and querying location data, such as coordinates, distances, and \n",
      "map layers. \n",
      "• \n",
      "Cloud Services: AWS, Google Cloud, and Azure provide infrastructure for load balancing, \n",
      "distributed data storage, and real-time data processing, essential for scaling LBAs. \n",
      "• \n",
      "Caching Systems: Redis and Memcached are used for caching frequently accessed data,\n",
      "\n",
      "\n",
      "\n",
      "especially with the advent of 5G, the adoption of cutting-edge scalability \n",
      "technologies will be essential. Future advancements will focus on reducing \n",
      "latency, enhancing fault tolerance, and integrating predictive load \n",
      "management, ensuring that LBAs remain responsive, efficient, and user-\n",
      "centric.  \n",
      "6.0 References \n",
      "• Google Cloud Scalability Solutions for Location-Based Applications. \n",
      "Google Cloud. https://cloud.google.com \n",
      "• Scaling Location-Based Services on AWS. Amazon Web Services. \n",
      "https://aws.amazon.com \n",
      "• Introduction to Spatial Databases: PostGIS and MongoDB. \n",
      "https://postgis.net, https://www.mongodb.com \n",
      "• Redis Caching for Scalable Applications. Redis Labs. https://redis.io\n",
      "\n",
      "\n",
      "\n",
      "Scalability in Location-Based Apps  \n",
      "A seminar report submitted to the  \n",
      "Walchand Institute of Technology, Solapur \n",
      "An Autonomous Institute \n",
      "for the degree of \n",
      "Bachelor of Technology  \n",
      "in \n",
      "Electronics & Computer Engineering  \n",
      "by \n",
      "Chetan Birajdar \n",
      "   Supervisor \n",
      "Dr. Ajit Gundale  \n",
      " \n",
      " \n",
      "Department of Electronics & Computer Engineering, \n",
      "Walchand Institute of Technology, Solapur \n",
      "Affiliated to Punyashlok Ahilyadevi Holkar  Solapur University, Solapur \n",
      "Walchand Hirachand Marg, \n",
      "Ashok Chowk, Solapur 413006. \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Name & Signature \n",
      "Dr. S.R. Gengaje \n",
      "         Project-Supervisor : Dr. Ajit Gundale \n",
      "Head\n",
      "\n",
      "\n",
      "\n",
      "Scalability is a fundamental requirement for the success of location-based \n",
      "applications, which need to manage large amounts of geospatial data and \n",
      "support millions of concurrent users. Through distributed databases, cloud \n",
      "services, load balancing, and caching mechanisms, LBAs can scale effectively to \n",
      "meet user demand. Advanced scalability strategies, like edge computing, \n",
      "predictive analytics, and serverless architectures, enable LBAs to perform \n",
      "reliably under varying loads. As the demand for LBAs continues to grow,\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"what is the system architecture\"\n",
    "docs = vector_store.search(query=question, search_type='similarity')\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"mmr\", search_kwargs = {'k': 3, \n",
    "                                                                          'fetch_k': 100,\n",
    "                                                                          'lambda_mult': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arraj\\AppData\\Local\\Temp\\ipykernel_19484\\3530216374.py:1: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  model = ChatOllama(model=\"llama2\", base_url=\"http://localhost:11434\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! It's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'model': 'llama2', 'created_at': '2025-01-22T11:20:51.9166733Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 7978886700, 'load_duration': 6965858400, 'prompt_eval_count': 21, 'prompt_eval_duration': 64313000, 'eval_count': 26, 'eval_duration': 930833000}, id='run-f96d57b5-8016-48b0-b0e4-5703d0849dd3-0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ChatOllama(model=\"llama2\", base_url=\"http://localhost:11434\")\n",
    "\n",
    "model.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arraj\\miniconda3\\envs\\torch\\Lib\\site-packages\\langsmith\\client.py:354: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "    You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question.\n",
    "    If you don't know the answer, just say that you don't know.\n",
    "    Answer in bullet points. Make sure your answer is relevant to the question and it is answered from the context only.\n",
    "    Always give in markdown format\n",
    "    Question: {question} \n",
    "    Context: {context} \n",
    "    Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever|format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the evaluation metrics mentioned in the context:\n",
      "\n",
      "* Latency: The time taken to process and respond to user requests is crucial for LBAs. Low latency is achieved by using caching and optimized data structures for geospatial queries.\n",
      "* Throughput: Measures the number of requests handled per second, a key indicator of an app’s ability to handle large user volumes.\n",
      "* Scalability: Assessed based on how well the system can handle increased workloads, using techniques like sharding and load balancing.\n",
      "* Fault Tolerance: Ensuring that the system remains operational even if certain servers or data centers fail.\n",
      "* Input/Output:\n",
      "\t+ Input: User location data, including latitude, longitude, and additional metadata (speed, altitude).\n",
      "\t+ Output: Responses like maps, nearby places, route information, and personalized location-based recommendations.\n",
      "\n",
      "The report also mentions the following strategies for improving scalability in location-based apps:\n",
      "\n",
      "* Horizontal scaling: Adding more servers or instances to handle increased traffic and data volume.\n",
      "* Distributed databases: Using multiple databases distributed across different servers or data centers to improve query performance and reduce latency.\n",
      "* Caching mechanisms: Employing caching to reduce server requests for frequently accessed data, improving response times.\n",
      "* Cloud services: Utilizing cloud computing services to handle large volumes of data and user traffic.\n",
      "* Load balancing: Distributing incoming traffic across multiple servers or instances to ensure that no single server is overwhelmed.\n",
      "* Geolocation clustering: Grouping users based on their location to reduce the number of requests and improve query performance.\n",
      "* Optimizing data structures for spatial queries: Using optimized data structures, such as quadtrees or grids, to improve query performance and reduce latency.\n"
     ]
    }
   ],
   "source": [
    "question = \"what is are the evaluation metrics\"\n",
    "\n",
    "output = rag_chain.invoke(question)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
